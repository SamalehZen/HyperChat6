## Objective\nReduce perceived and real TTFB for complex prompts by streaming earlier, instrumenting timings, and tuning server-side buffering.\n\n## Changes\n- Add fine-grained timing headers: X-Timing-Auth, X-Timing-BodyParse, X-Timing-KV, X-Timing-Geo, X-Timing-PreStream, plus X-Model-Provider and X-Model-Id.\n- Emit immediate SSE 'init' event on stream start (<200ms target).\n- Add SSE 'metrics' events: t_workflow_start, t_first_event, t_first_model_chunk, t_first_flush, provider/model/mode/threadId, prompt_length, messages_count.\n- Include workflow.getTimingSummary() and metrics in final 'done' event.\n- Tune ChunkBuffer for answers: RESPONSE_BUFFER_THRESHOLD (default 16, can be 1 for tests) and RESPONSE_BUFFER_INTERVAL_MS (default 100ms, min 100ms) to flush small chunks at ~10Hz max.\n- Instrument generateText to surface t_first_model_chunk via onFirstChunk; wired to workflow metrics.\n- Guard Langfuse initialization behind env and after first event.\n- Ensure PostHog capture/flush are non-blocking.\n\n## Acceptance\n- First SSE event (init/metrics) <200ms; first answer token <1s typically (provider latency excluded).\n- Reliable metrics to compute TTFB_model and TTFB_answer, plus auth/KV/geo sub-timings.\n\n## Env flags\n- RESPONSE_BUFFER_THRESHOLD\n- RESPONSE_BUFFER_INTERVAL_MS\n\nSee MODIFICATIONS_SUMMARY.md for details.